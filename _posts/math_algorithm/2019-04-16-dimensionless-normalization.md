---
layout: post
title: 置信区间&置信率
category: 数学和算法
keywords: 去量纲,数据归一化
---

## 概念
### 归一化
1. 把数据变成(０，１)或者（1,1）之间的小数。主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速。
2. 把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。

### 标准化
在机器学习中，我们可能要处理不同种类的资料，例如，音讯和图片上的像素值，这些资料可能是高维度的，资料标准化后会使每个特征中的数值平均变为0(将每个特征的值都减掉原始资料中该特征的平均)、标准差变为1，这个方法被广泛的使用在许多机器学习算法中(例如：支持向量机、逻辑回归和类神经网络)。


### 中心化
平均值为0，对标准差无要求
数据分标准化是将数据按比例缩放，使之落入一个小的特定区间，在某些比较和评价的指标处理中经常会用到，去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权。

### 区别
* 归一化和标准化的区别：归一化是将样本的特征值转换到同一量纲下把数据映射到[0,1]或者[-1, 1]区间内，仅由变量的极值决定，因区间放缩法是归一化的一种。标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，转换为标准正态分布，和整体样本分布相关，每个样本点都能对标准化产生影响。它们的相同点在于都能取消由于量纲不同引起的误差；都是一种线性变换，都是对向量X按照比例压缩再进行平移。

* 标准化和中心化的区别：标准化是原始分数减去平均数然后除以标准差，中心化是原始分数减去平均数。 所以一般流程为先中心化再标准化。

## 实现

###  归一化

```
（1）Min-Max Normalization
   x' = (x - X_min) / (X_max - X_min)
```

```   
（2）平均归一化
   x' = (x - μ) / (MaxValue - MinValue)
   
  （1）和（2）有一个缺陷就是当有新数据加入时，可能导致max和min的变化，需要重新定义。
```

```
（3）非线性归一化
  1）对数函数转换：y = log10(x)
  2）反余切函数转换：y = atan(x) * 2 / π
  （3）经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 log、指数，正切等。需要根据数据分布的情况，决定非线性函数的曲线，比如log(V, 2)还是log(V, 10)等。
```


### 标准化

```
（1）Z-score规范化（标准差标准化 / 零均值标准化）
  x' = (x - μ)／σ
```

### 中心化
``` 
  x' = x - μ
```

## 什么时候用归一化？什么时候用标准化？
* 如果对输出结果范围有要求，用归一化。
* 如果数据较为稳定，不存在极端的最大最小值，用归一化。
* 如果数据存在异常值和较多噪音，用标准化，可以间接通过中心化避免异常值和极端值的影响。
   

### 参考资料
* [模式识别之样本数据归一化（Normalization）与标准化（Standardization）](https://blog.csdn.net/u011650143/article/details/71515927)
* [归一化 （Normalization）、标准化 （Standardization）和中心化/零均值化 （Zero-centered）
](https://www.jianshu.com/p/95a8f035c86c)
* [特征工程中的「归一化」有什么作用？](https://www.zhihu.com/question/20455227/answer/370658612)